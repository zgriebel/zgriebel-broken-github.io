---
title: "Classification Modeling"
author: "Zach"
date: '2023-10-09'
output:
  pdf_document: default
  html_document: default
---
---
title: "Classification Modeling"
format: html
editor: visual
---

Classification means when the prediction is not a statistical number. In this case the prediction a category. The NVO case has the prediction being if a person responds to mailing which is a category.

The benefit of using modeling would be to focus resources on opportunities with higher potential. If a model can find people with a higher chance of responding the resources can be focused there.

The most important for evaluating these models is Precision and Sensitivity. Precision(Pos pred values) the model says yes, how often is that correct. We are looking to identify potential Yes. We want to utilize our resources on correct yes responses. Sensitivity is the rate of true positives captured by the program.

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE )
rm(list = ls())
```

```{r}
library(tidyverse)
library(rpart)
library(caret)
suppressWarnings(
library(DALEX))
library(ggthemes)
library(pROC)
library(patchwork)
library(corrplot)
library(glmnet)
```

```{r}
donor <- read.csv('donors.csv')
```

```{r}
glimpse(donor)
```

```{r}
sapply(donor, function(x) sum(is.na(x)))
```

We see there are 22 variables and 95,412 observations. Many are numeric however there are a few that need to be adjusted to be factors. There are logical columns, those will also be mutated to be factors.

There are 83,000 NAs with children. For that reason I will drop that column, that is to many NAs to make an assumption to make decisions from.

It can be assumed that `incomeRating` and `Welathrating` derive from `eachother`. Wealth rating has a lot more NAs so we will drop that column as well.

If home owner is NA it will be assumed that the answer is False

```{r}

donor = donor %>% select(-numberChildren, -wealthRating, -urbanicity, -gender, -state, - socioEconomicStatus)
donor = donor %>%
  mutate(incomeRating = ifelse(is.na(incomeRating),
                                 4,
                                 incomeRating))
donor = donor %>% 
  mutate(isHomeowner = ifelse(is.na(isHomeowner),
                              FALSE,
                              isHomeowner))

```

```{r}
donor = donor %>%
  mutate(respondedMailing = as.factor(as.numeric(respondedMailing))) %>%
  mutate(isHomeowner = as.numeric(isHomeowner))
```

This is setting our response variable to a factor

```{r}
library(corrplot)
na.omit(donor) %>%
  keep(is.numeric) %>%
  cor() %>%
  corrplot()
```

There are a couple interesting correlations here. `Total Giving Amount` and `Number of Gifts` are strongly correlated which makes sense. `Smallest Gift` and `Number of Gifts` are correlated. That make sense because for example is a donor gives quite often the avarage size of the donation would be smaller because it is more frequent. `Years Since First donation` and `Total Giving Amount` makes sense. The longer you have been a donor the more you will have donated. `Average Gift` is correlated with the statistics with largest and smallest gift.

```{r}
sapply(donor, function(x) sum(is.na(x)))
```

Now age is the only variable with NAs left

```{r}
ggplot(donor) + geom_histogram(aes(x = age)) 
```

```{r}
ggplot(donor)+ geom_boxplot(aes(x = age))
```

There are 20000 missing Values for age. However it is a variable we would like to keep. For that reason it is important that we keep The age distribution appears Bimodel. The disribution between the the modes apear very comparable. We will replace the NAs in age with the average. This will not affect the average and allow us to keep a lot more data.

```{r}
donor = donor %>%
  mutate(age = ifelse(is.na(age),
                      median(age, na.rm = TRUE),
                      age))
```

```{r}
table(donor$respondedMailing)
```

This is very disproportional. We will need to fix this.

```{r}
donor <- donor %>% mutate(inHouseDonor = ifelse(inHouseDonor == TRUE, 1, 0)) %>%
mutate(plannedGivingDonor = ifelse(plannedGivingDonor == TRUE, 1, 0)) %>%
mutate(sweepstakesDonor =ifelse(sweepstakesDonor == TRUE, 1,0)) %>% 
mutate(P3Donor =ifelse(P3Donor == TRUE, 1,0))

```

Make some classification columns numerical

```{r}
set.seed(4)
samp = caret::createDataPartition(donor$respondedMailing, p = 0.7, list = FALSE)
train = donor[samp,]
test = donor[-samp,]
```

seperate into training and test data

```{r}
(train$respondedMailing) %>% table() %>% prop.table()
test$respondedMailing %>% table() %>% prop.table()
```

We will use smote to get our data more proportionally accurate

```{r}
#Smote Version
library(performanceEstimation)
set.seed(4959)
smote_train = smote(respondedMailing ~ .,
                    data = train)

table(smote_train$respondedMailing)
```

```{r}
X = as.matrix(dplyr::select(smote_train, -respondedMailing))
Y = smote_train$respondedMailing
```

```{r}

cv_lasso = cv.glmnet(X, as.double(Y), type.measure = "class",  family ="binomial")

```

```{r}
plot(cv_lasso)
```

There is a local minima at lamba = 3.6

building the tree

```{r}
ctrl = caret::trainControl(method = "repeatedcv", number = 5, repeats = 30)
set.seed(1)
smote_tree = caret::train(respondedMailing ~ ., 
             data = smote_train, 
             method = "rpart",
             metric = "Kappa",
             trControl = ctrl,
             tuneGrid = expand.grid(cp = seq(0.0, 0.1, 0.005)))

plot(smote_tree)
```

```{r}
smote_tree
```


Best Kappa is at .9

```{r}
#rpart.plot::rpart.plot(smote_tree$finalModel)

```

```{r}
testing_mat = data.matrix(test)
lasso_test_class = predict(cv_lasso, testing_mat[,1:15], s=cv_lasso$lambda.min)
```

```{r}
lasso_cm = confusionMatrix(data = as.factor(ifelse(lasso_test_class > 0.5, 1, 0)), reference = as.factor(testing_mat[,15]), positive = "1")
lasso_cm
```

At first glance is would appear that our lasso model did not perform very well. The accuracy is not good, the sensitivity is very low. However the main evaluater we care about is Pos Pred Value (precision). This tells us when the model predicts yes, how often is it correct. While a 52% chance of being correct does not sound good. It is signficantly more efficient than taking random guesses.

```{r}

smote_test_class = predict(smote_tree, newdata = test, type="raw")
smote_test_prob = predict(smote_tree, newdata = test, type="prob")[,1]
```

```{r}
#Tree Model
smote_cm = confusionMatrix(smote_test_class, test$respondedMailing, positive = "1")
smote_cm
```

The Pos Pred Value of our tree was really not good. This model currently is too specific. This can be seen with a higher sensitivity meaning the rate of true positives captured by the program. This can be good because it means it will capture more positive responses, but with a lower precision will mean less efficient. Our tree model did significantly better.

```{r}
par(pty="s")
lasso_roc = roc(testing_mat[,16], lasso_test_class, 
                     plot=TRUE, print.auc=TRUE, 
                     col="green", lwd=3, legacy.axes=TRUE)
smote_roc = roc(test$respondedMailing ~ smote_test_prob,
                plot=TRUE, print.auc=TRUE, print.auc.y=0.7,
                col = "black", lwd=3, legacy.axes=TRUE, add=TRUE)

legend("bottomright", legend=c("Lasso Model", "Tree"),
       col = c("green", "black"), lwd=3)
```

This tells us that our Lasso Model appears to preform slightly better overall.

```{r}
lasso_explain = DALEX::explain(model = cv_lasso,
                               data = testing_mat[,1:15],
                               y = testing_mat[,16]=="1",
                               type='classification',
                               label='Lasso Model')

lasso_perf = DALEX::model_performance(lasso_explain, cutoff = 0.5)

```

```{r}
p1 = plot(lasso_perf, geom = "prc")
p2 = plot(lasso_perf, geom = "gain")
p1 + p2
```

With a similar proportion as our current data 50,000 people would mean there are 2,535 people that would respond to mailing. With a precision of .52 this would mean about 1268 of those people of those would be successfully identified. This is significantly better than at random however there are still a lot of missed opportunities.
